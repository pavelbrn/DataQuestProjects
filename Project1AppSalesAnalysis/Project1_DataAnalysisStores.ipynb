{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AppStore and Google Play free apps Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the code below we open `AppleStore.csv` and `googleplaystore.csv`\n",
    "- Both file objects are then converted into lists using the csv reader() and the built-in list() functions\n",
    "- Apple store data set: https://www.kaggle.com/lava18/google-play-store-apps\n",
    "- Google Play data set: https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "app_store = open('AppleStore.csv')\n",
    "appstore_read= reader(app_store)\n",
    "app_store_list = list(appstore_read)\n",
    "app_store_header = app_store_list[0]\n",
    "appstore_data = app_store_list[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_store = open('googleplaystore.csv')\n",
    "google_read = reader(google_store)\n",
    "google_list=list(google_read)\n",
    "google_header = google_list[0]\n",
    "google_data=google_list[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `explore_data()` function takes in a list and returns a spliced list within the defined parameters\n",
    "- Setting the third parameter to `True` inside `explore_data()` returns the amount of rows and columns inside the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n",
    "        print('\\n') # adds a new (empty) line after each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 10841\n",
      "Number of columns: 13\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows: 7197\n",
      "Number of columns: 16\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explore_data(google_data,0,1, True)\n",
    "explore_data(appstore_data,0,1,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Row 10472(excluding header) has a missing 'Category' column. We remove this row from the gogle data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n"
     ]
    }
   ],
   "source": [
    "print(google_data[10472])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del google_data[10472]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['osmino Wi-Fi: free WiFi', 'TOOLS', '4.2', '134203', '4.1M', '10,000,000+', 'Free', '0', 'Everyone', 'Tools', 'August 7, 2018', '6.06.14', '4.4 and up']\n"
     ]
    }
   ],
   "source": [
    "print(google_data[10472])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The google data set contains 1181 duplicate entries, we check by running the `duplicate_apps()` function on both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google duplicates: 1181\n",
      "Apple duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "def duplicate_apps(dataset):\n",
    "    duplicate_set=[]\n",
    "    unique_apps = []\n",
    "    for app in dataset[1:]:\n",
    "        #print(len(app))\n",
    "        # First column contains name:\n",
    "        name = app[0]\n",
    "        if name in unique_apps:\n",
    "            duplicate_set.append(name)\n",
    "        else:\n",
    "            unique_apps.append(name)\n",
    "   # length = len(duplicate_apps)\n",
    "   \n",
    "    return duplicate_set\n",
    "\n",
    "google_duplicates = duplicate_apps(google_data)\n",
    "apple_duplicates = duplicate_apps(appstore_data)\n",
    "print('Google duplicates: '+str(len(google_duplicates)))\n",
    "print('Apple duplicates: '+str(len(apple_duplicates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Duplicate entries will be removed using the review number as a criteria, since this will show the newest entry. Only a duplicate with the highest number of reviews will be kept, the rest will be discarded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9659\n"
     ]
    }
   ],
   "source": [
    "def remove_duplicates(dataset):\n",
    "    android_clean = []\n",
    "    already_added=[]\n",
    "    \n",
    "    reviews_max = {}\n",
    "    for app in dataset:\n",
    "        # First column contains name:\n",
    "        # Third column containt review count\n",
    "        app_name = app[0]\n",
    "        reviews = float(app[3])\n",
    "        \n",
    "        # Do not use an else statement here because if rereviews>reviews_max[app_name] is False\n",
    "        # then it will update the reviews falsely inside the else condition.\n",
    "        if app_name in reviews_max and reviews>reviews_max[app_name]:\n",
    "            reviews_max[app_name] = reviews\n",
    "        if app_name not in reviews_max:\n",
    "            reviews_max[app_name] = reviews\n",
    "            \n",
    "    for app in dataset:\n",
    "        app_name = app[0]\n",
    "        reviews = float(app[3])\n",
    "        \n",
    "        # include 'app_name not in already_added' otherwise we will be counting\n",
    "        # duplicate reviews as well.\n",
    "        if reviews == reviews_max[app_name] and app_name not in already_added:\n",
    "            android_clean.append(app)\n",
    "            already_added.append(app_name)\n",
    "            \n",
    "    return android_clean\n",
    "            \n",
    "    #print(len(reviews_max))\n",
    "    #print(len(android_clean))\n",
    "    \n",
    "            \n",
    "android_no_duplicates= remove_duplicates(google_data)\n",
    "print(len(android_no_duplicates))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the cell below we remove all apps containing non-Latin characters from the data set\n",
    "- The data that will be analyzed needs to be targeted at English speaking audiences\n",
    "- We test our first function for removing characters as an excercise from DQ\n",
    "- It is important to note that app names in the apple data set are in column index 2, so our function has to include the specific name index for that data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6183\n"
     ]
    }
   ],
   "source": [
    "def get_latin_char_apps(dataset,name_index):\n",
    "    android_cleaned_eng=[]\n",
    "    \n",
    "    for app in dataset:\n",
    "        name = app[name_index]\n",
    "        if check_characters(name):\n",
    "            android_cleaned_eng.append(app)\n",
    "            #print(name)\n",
    "    #print(android_cleaned_eng)\n",
    "    return android_cleaned_eng\n",
    "\n",
    "    \n",
    "\n",
    "def check_characters(string):\n",
    "    max_non_latin_char = 0\n",
    "    for character in string:\n",
    "        if ord(character) >=127:\n",
    "            #print(\"non-Latin characters detected\"+str(max_non_latin_char))\n",
    "            max_non_latin_char +=1\n",
    "            if max_non_latin_char>3:\n",
    "                #print(string)\n",
    "                return False\n",
    "    return True\n",
    "    \n",
    "            \n",
    "android_latin_char = get_latin_char_apps(android_no_duplicates,0)\n",
    "app_store_latin_char = get_latin_char_apps(appstore_data,1)\n",
    "\n",
    "print(len(app_store_latin_char))\n",
    "\n",
    "#check_characters('爱奇艺PPS -《欢乐颂2》电视剧热播')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our current cleaned datasets are `android_latin_char` and `app_store_latin_char`.\n",
    "- These contain no duplicated and only apps with Latin characters\n",
    "- In the next cell we isolate all free apps found in the Apple and Adroid stores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n"
     ]
    }
   ],
   "source": [
    "# Printing the headers for column reference:\n",
    "print(app_store_header)\n",
    "print('\\n')\n",
    "print(google_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8864\n",
      "3222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_free_apps(dataset, index):\n",
    "    free_apps_list = []\n",
    "    \n",
    "    for row in dataset:\n",
    "        free_apps = row[index]\n",
    "        #print(free_apps)\n",
    "        if free_apps == '0' or free_apps == '0.0':\n",
    "            free_apps_list.append(row)\n",
    "    #print(free_apps_list)\n",
    "    \n",
    "    return free_apps_list\n",
    "\n",
    "#print(android_latin_char)\n",
    "\n",
    "appstore_free = get_free_apps(app_store_latin_char,4)\n",
    "android_free = get_free_apps(android_latin_char,7)\n",
    "\n",
    "print(len(android_free))\n",
    "print(len(appstore_free))\n",
    "print(\"\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
